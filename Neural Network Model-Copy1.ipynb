{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(20, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "        # Pass data through conv1\n",
    "        x = self.conv1(x)\n",
    "        # Use the rectified-linear activation function over x\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Run max pooling over x\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Pass data through dropout1\n",
    "        x = self.dropout1(x)\n",
    "        # Flatten x with start_dim=1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Pass data through fc1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply softmax to x\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3863, -2.2417, -2.2753, -2.4834, -2.3437, -2.2135, -2.2857, -2.2556,\n",
      "         -2.2604, -2.3085]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyongliu/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# Equates to one random 28x28 image\n",
    "random_data = torch.rand((1, 1, 28, 28))\n",
    "\n",
    "my_nn = Net()\n",
    "result = my_nn(random_data)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model, validation and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data_loader):\n",
    " \n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        a2 = model(X.view(-1, 3, 224, 224))\n",
    "        loss = criterion(a2, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*X.size(0)\n",
    "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
    "        optimizer.step()  \n",
    "        \n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
    "  \n",
    "def validate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    validation_loss, validation_accuracy = 0., 0.\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            a2 = model(X.view(-1, 3, 224, 224))\n",
    "            loss = criterion(a2, y)\n",
    "            validation_loss += loss*X.size(0)\n",
    "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
    "            \n",
    "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
    "  \n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    ys, y_preds = [], []\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            a2 = model(X.view(-1, 3, 224, 224))\n",
    "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "            ys.append(y.cpu().numpy())\n",
    "            y_preds.append(y_pred.cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(30):\n",
    "    logs = {}\n",
    "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "    logs['' + 'log loss'] = train_loss.item()\n",
    "    logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "    validation_loss, validation_accuracy = validate(model, criterion, test_loader)\n",
    "    logs['val_' + 'log loss'] = validation_loss.item()\n",
    "    logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
    "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.parameters()\n",
    "path = \"Descent_full_training.pt\"\n",
    "torch.save(model.state_dict,path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
